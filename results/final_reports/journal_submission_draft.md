# JOURNAL SUBMISSION DRAFT
## IEEE Transactions on Learning Technologies (or similar venue)

---

**Title:** Comparative Evaluation of ChatGPT-4o and Gemini-1.5-Pro for Automated Indonesian Essay Scoring: A Multi-Trial Reliability Study

**Authors:** [To be filled] (Samsidar, Syaiful Bachri Mustamin, Siti Fatmah)

**Affiliations:** Institut Sains Teknologi dan Kesehatan Aisyiyah Kendari

**Corresponding Author:** Syaiful Bachri Mustamin 

**Email:** syaifulbachri@mail.ugm.ac.id

---

## ABSTRACT (150-200 words)

This study presents a comprehensive evaluation of Large Language Model (LLM)-based automated essay scoring (AES) for Indonesian language assessment. We compared ChatGPT-4o and Gemini-1.5-Pro across 1398 essay gradings with 10 independent trials per model. Gemini-1.5-Pro demonstrated superior performance with 80.4% exact agreement versus 69.1% for ChatGPT-4o (McNemar p < 0.0001). Both models exhibited outstanding inter-rater reliability (ICC > 0.98, Cronbach's α > 0.98) with zero critical errors (±2+ grades). The lenient prompting strategy yielded QWK scores of 0.627-0.716, indicating substantial agreement with expert graders. These findings establish LLM-based AES as a viable, scalable solution for Indonesian language education, addressing critical needs in low-resource language contexts. Our results provide evidence-based recommendations for educational institutions considering AI-assisted assessment deployment.

**Index Terms—** Automated Essay Scoring, Large Language Models, ChatGPT, Gemini, Indonesian Language, Educational Assessment, Inter-Rater Reliability, Natural Language Processing

---

## I. INTRODUCTION

*[3-4 paragraphs establishing context, problem, gap, and contribution]*

- Paragraph 1: Educational assessment challenges, focus on essay grading
- Paragraph 2: Rise of LLMs and potential for AES
- Paragraph 3: Gap in Indonesian language AES research
- Paragraph 4: Study contribution and paper organization

---

## II. RELATED WORK

*[3-4 subsections reviewing relevant literature]*

**A. Automated Essay Scoring Systems**
- Classical AES approaches
- Machine learning-based systems
- Neural network approaches

**B. Large Language Models in Education**
- ChatGPT applications in assessment
- Gemini/Bard in educational contexts
- Comparative studies

**C. AES for Non-English Languages**
- Low-resource language challenges
- Indonesian language NLP
- Cross-lingual assessment

**D. Reliability and Validity in AES**
- Inter-rater reliability metrics
- Validation methodologies
- Ethical considerations

---

## III. METHODOLOGY

**A. Dataset Description**
- 10 students
- 7 questions per student
- 10 independent trials
- 1398 valid expert-AES pairs
- 5-point grading scale (A, B, C, D, E)

**B. Models and Configuration**
- ChatGPT-4o (GPT-4 Omni)
- Gemini-1.5-Pro
- Lenient prompting strategy
- Detailed rubric integration

**C. Evaluation Metrics**
- Agreement: EA, AA, Cohen's κ, QWK
- Reliability: ICC(2,k), Cronbach's α, Fleiss' κ
- Statistical tests: t-test, Wilcoxon, McNemar, Cohen's d

**D. Experimental Procedure**
- Multi-trial design (10 independent runs)
- Blind evaluation protocol
- Cross-validation approach

---

## IV. RESULTS

**A. RQ1: Agreement with Expert Grading**
*[Table 1: Agreement Metrics]*
*[Figure 1: Confusion Matrices]*
*[Figure 2: Agreement Comparison]*

**B. RQ2: Inter-Rater Reliability**
*[Table 2: Reliability Metrics]*
*[Figure 3: ICC by Question]*
*[Figure 4: Consistency Heatmaps]*

**C. RQ3: Model Comparison**
*[Table 3: Statistical Tests]*
*[Figure 5: Win-Loss-Tie Analysis]*
*[Figure 6: Score Distribution Comparison]*

**D. RQ4: Error Analysis**
*[Table 4: Error Classification]*
*[Figure 7: Error Distribution]*
*[Figure 8: Error Magnitude]*

**E. RQ5: Practical Implications**
*[Table 5: Deployment Scenarios]*
*[Figure 9: Scalability Projections]*

---

## V. DISCUSSION

**A. Performance Comparison**
- Gemini's 11.3pp advantage
- Statistical significance (McNemar p < 0.0001)
- Practical implications of performance gap

**B. Reliability & Consistency**
- Outstanding ICC values (>0.98)
- Implications for high-stakes assessment
- Comparison with human inter-rater reliability

**C. Error Patterns and Safety**
- Zero critical errors
- Over-grading tendency
- Mitigation strategies

**D. Implications for Indonesian Education**
- Scalability potential
- Cost-effectiveness
- Teacher workload reduction

**E. Limitations and Future Work**
- Dataset limitations
- Generalizability considerations
- Future research directions

---

## VI. CONCLUSIONS

*[2-3 paragraphs summarizing key findings, contributions, and recommendations]*

Key takeaways:
1. Gemini-1.5-Pro is superior for Indonesian AES (80.4% vs 69.1%)
2. Both models achieve excellent reliability (ICC > 0.98)
3. Zero critical errors establish deployment safety
4. System ready for practical implementation
5. First comprehensive Indonesian AES comparison study

---

## ACKNOWLEDGMENTS

[To be filled - funding sources, contributors, institutions]

---

## REFERENCES

[References to be compiled - suggested categories:]
- [1-5] AES systems and methods
- [6-10] LLM applications in education
- [11-15] Indonesian NLP and education
- [16-20] Reliability and validation methods
- [21-25] Comparative AI system evaluations

---

## AUTHOR BIOGRAPHIES

[To be filled]

---

## SUPPLEMENTARY MATERIALS

Available online:
- Complete dataset description
- Detailed statistical analyses
- All visualization figures (22 total)
- Rubric specifications
- Prompt templates
- Replication package

---

*End of Journal Draft*
