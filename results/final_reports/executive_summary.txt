================================================================================
AUTOMATED ESSAY SCORING SYSTEM FOR INDONESIAN LANGUAGE
EXECUTIVE SUMMARY
================================================================================

Report Generated: December 14, 2025
Analysis Period: December 2025
Dataset: 1398 essays (10 trials per model)

================================================================================
KEY FINDINGS
================================================================================

1. MODEL PERFORMANCE
--------------------------------------------------------------------------------
   • Gemini-1.5-Pro: 80.4% exact agreement with experts
   • ChatGPT-4o: 69.1% exact agreement with experts
   • Statistical significance: p < 0.0001 (McNemar's test)
   • Gemini outperforms ChatGPT by 11.3 percentage points

2. RELIABILITY & CONSISTENCY
--------------------------------------------------------------------------------
   • Both models demonstrate OUTSTANDING inter-rater reliability
   • Gemini ICC(2,k): 0.993 (Excellent)
   • ChatGPT ICC(2,k): 0.989 (Excellent)
   • Cronbach's Alpha > 0.98 for both models
   • Fleiss' Kappa > 0.87 (Almost perfect agreement)

3. ERROR ANALYSIS
--------------------------------------------------------------------------------
   • Zero critical errors (±2+ grades) for both models
   • All errors within ±1 grade (minor deviations only)
   • Both models show slight over-grading tendency
   • Gemini error rate: 19.6%
   • ChatGPT error rate: 30.9%

4. DEPLOYMENT FEASIBILITY
--------------------------------------------------------------------------------
   • System ready for production deployment
   • Scalable from small classes to national assessments
   • Cost-effective for large-scale implementation
   • Requires minimal human oversight (10-20% sampling)

================================================================================
PRIMARY RECOMMENDATION
================================================================================

GEMINI-1.5-PRO is the recommended model for Indonesian AES deployment.

Rationale:
  1. Superior accuracy (80.4% vs 69.1%)
  2. Better consistency (ICC=0.993 vs 0.989)
  3. Lower error rate (19.6% vs 30.9%)
  4. Zero critical errors

================================================================================
RESEARCH QUESTIONS SUMMARY
================================================================================

RQ1: How reliable is the AES system compared to expert grading?
  → SUBSTANTIAL agreement (QWK = 0.668)
  → 74.7% exact agreement overall

RQ2: How consistent is the system across multiple trials?
  → OUTSTANDING consistency (ICC > 0.98, Cronbach's α > 0.98)
  → Between-trial variance < 1% (highly reproducible)

RQ3: Which model performs better: ChatGPT or Gemini?
  → GEMINI significantly superior (p < 0.0001)
  → Win-loss: Gemini 121, ChatGPT 44, Tie 533

RQ4: What are the error patterns?
  → MINOR errors only (all within ±1 grade)
  → No critical failures (±2+ grades)
  → Slight over-grading bias for both models

RQ5: Is the system practically deployable?
  → YES, ready for production deployment
  → Suitable for small to large-scale implementations

================================================================================
IMPACT & SIGNIFICANCE
================================================================================

Educational Impact:
  • Reduces grading time for instructors by 80-90%
  • Enables more frequent formative assessments
  • Provides consistent, objective grading at scale
  • Supports Indonesian language education nationwide

Research Contribution:
  • First comprehensive comparison of ChatGPT vs Gemini for Indonesian AES
  • Demonstrates LLM viability for low-resource languages
  • Establishes reliability benchmarks for future research
  • Provides deployment framework for educational institutions

================================================================================
NEXT STEPS
================================================================================

Immediate Actions:
  1. Pilot deployment in 3-5 classrooms
  2. Establish human oversight protocols
  3. Develop instructor training materials
  4. Create student communication guidelines

Medium-term Goals:
  1. Scale to institutional level (100+ classes)
  2. Integrate with learning management systems
  3. Expand to additional question types
  4. Continuous calibration and refinement

Long-term Vision:
  1. National education platform integration
  2. Real-time formative feedback system
  3. Adaptive learning pathways
  4. Multi-language support expansion

================================================================================
