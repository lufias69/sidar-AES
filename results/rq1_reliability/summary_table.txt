================================================================================
RQ1: RELIABILITY VS EXPERT GRADING - SUMMARY TABLE
================================================================================

OVERALL AGREEMENT METRICS
--------------------------------------------------------------------------------

Model                N        EA (%)     AA (%)     Kappa      QWK       
--------------------------------------------------------------------------------
ChatGPT-Lenient      700      69.1       100.0      0.436      0.627     
Gemini-Lenient       698      80.4       100.0      0.611      0.716     
Combined (All)       1398     74.7       100.0      0.520      0.668     

================================================================================
PER-GRADE PERFORMANCE
================================================================================


ChatGPT-Lenient:
--------------------------------------------------------------------------------
Grade    Support    Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
A        10         0.222        1.000        0.364       
B        410        0.805        0.805        0.805       
C        220        0.581        0.636        0.607       
D        60         1.000        0.067        0.125       

Gemini-Lenient:
--------------------------------------------------------------------------------
Grade    Support    Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
A        10         0.000        0.000        0.000       
B        409        0.856        0.976        0.912       
C        219        0.698        0.740        0.718       
D        60         0.000        0.000        0.000       

Combined (All):
--------------------------------------------------------------------------------
Grade    Support    Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
A        20         0.222        0.500        0.308       
B        819        0.832        0.890        0.860       
C        439        0.638        0.688        0.662       
D        120        1.000        0.033        0.065       

================================================================================
INTERPRETATION
================================================================================

Exact Agreement (EA):
  - Percentage of exact matches between AES and expert grades
  - Benchmark: >70% is good for educational assessment

Adjacent Agreement (AA):
  - Percentage within Â±1 grade level
  - Benchmark: >90% is acceptable

Cohen's Kappa:
  - 0.00-0.20: Slight agreement
  - 0.21-0.40: Fair agreement
  - 0.41-0.60: Moderate agreement
  - 0.61-0.80: Substantial agreement
  - 0.81-1.00: Almost perfect agreement

Quadratic Weighted Kappa (QWK):
  - Similar to Cohen's Kappa but penalizes larger disagreements more
  - Preferred for ordinal grades (A, B, C, D)
  - Same interpretation thresholds as Cohen's Kappa

================================================================================
